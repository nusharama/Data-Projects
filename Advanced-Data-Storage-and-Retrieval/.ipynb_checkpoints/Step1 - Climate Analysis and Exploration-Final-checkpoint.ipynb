{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect Tables into SQLAlchemy ORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func, inspect\n",
    "from sqlalchemy import Column, Integer, String, Float, Date, Text\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "Base = declarative_base() \n",
    "from flask import Flask, jsonify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_path = \"hawaii.sqlite\"\n",
    "engine = create_engine(f\"sqlite:///{database_path}\")\n",
    "# engine = create_engine(f\"sqlite:///Advanced-Data-Storage-and-Retrieval/hawaii.sqlite\")\n",
    "conn = engine.connect()\n",
    "Base.metadata.create_all(conn)\n",
    "session = Session(bind=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will reflect that database (set up the metadata of what tables we have)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reflect an existing database into a new model\n",
    "Base = automap_base()\n",
    "# reflect the tables\n",
    "Base.prepare(engine, reflect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['measurement', 'station']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can view all of the classes that automap found\n",
    "Base.classes.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect Tables\n",
    "We note that we have two tables, measurement and station. We will save classes of these to be able to reference the tables. Presumably, these correspond to actual weather measurements and information about specific stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save references to each table\n",
    "Measurement = Base.classes.measurement\n",
    "Station = Base.classes.station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id INTEGER\n",
      "station TEXT\n",
      "date TEXT\n",
      "prcp FLOAT\n",
      "tobs FLOAT\n"
     ]
    }
   ],
   "source": [
    "#inspect measurement schema\n",
    "inspector = inspect(engine)\n",
    "inspector.get_table_names()\n",
    "columns = inspector.get_columns('measurement')\n",
    "for column in columns:\n",
    "    print(column[\"name\"], column[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id INTEGER\n",
      "station TEXT\n",
      "name TEXT\n",
      "latitude FLOAT\n",
      "longitude FLOAT\n",
      "elevation FLOAT\n"
     ]
    }
   ],
   "source": [
    "# Inspect stations schema\n",
    "inspector = inspect(engine)\n",
    "inspector.get_table_names()\n",
    "columns = inspector.get_columns('station')\n",
    "for column in columns:\n",
    "    print(column[\"name\"], column[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our session (link) from Python to the DB\n",
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Trip DatesÂ¶\n",
    "We need to pick trip dates. We will use a January 2019 trip time, assuming that crowds will dip after the holiday season. So, we will go on June 4th, 2019 and return on June 20th, 2019.\n",
    "\n",
    "We will save these as date objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save start date and end date\n",
    "start_date = dt.date(2019, 6, 4)\n",
    "end_date = dt.date(2019, 6, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Climate Analysis\n",
    "We will do some basic exploratory analysis of the data first.\n",
    "\n",
    "Precipitation Analysis First, we will look at precipitation data for the last year.\n",
    "\n",
    "As we don't know how dates are formatted, we will inspect them first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2010-01-01',), ('2010-01-02',), ('2010-01-03',), ('2010-01-04',), ('2010-01-06',)]\n",
      "[('2010-01-01',), ('2010-01-02',), ('2010-01-03',), ('2010-01-04',), ('2010-01-06',)]\n",
      "[('2010-01-01',), ('2010-01-02',), ('2010-01-03',), ('2010-01-04',), ('2010-01-06',)]\n",
      "[('2010-01-01',), ('2010-01-02',), ('2010-01-03',), ('2010-01-04',), ('2010-01-06',)]\n",
      "[('2010-01-01',), ('2010-01-02',), ('2010-01-03',), ('2010-01-04',), ('2010-01-06',)]\n"
     ]
    }
   ],
   "source": [
    "#inspect how the dates are formatted\n",
    "sample_date = session.query(Measurement.date).limit(5).all()\n",
    "for result in sample_date:\n",
    "    print(sample_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-08-23'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dates are formatted as YYYY-MM-DD\n",
    "#we will get the maximum date after formatting the dates appropriately\n",
    "#first is used as there are multiple measurements on the same day\n",
    "max_date = session.query(func.max(func.strftime(\"%Y-%m-%d\", Measurement.date))).limit(5).all()\n",
    "max_date[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#access all precipitation data from the last year (as the end of the data is our endpoint, we only need one comparison)\n",
    "precip_data = session.query(func.strftime(\"%Y-%m-%d\", Measurement.date), Measurement.prcp).\\\n",
    "    filter(func.strftime(\"%Y-%m-%d\", Measurement.date) >= dt.date(2016, 8, 23)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precipitation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-08-23</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-24</th>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-25</th>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-26</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-27</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            precipitation\n",
       "date                     \n",
       "2016-08-23           0.00\n",
       "2016-08-24           0.08\n",
       "2016-08-25           0.08\n",
       "2016-08-26           0.00\n",
       "2016-08-27           0.00"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load as a dataframe\n",
    "precip_df = pd.DataFrame(precip_data, columns = ['date', 'precipitation'])\n",
    "\n",
    "#set index\n",
    "precip_df.set_index('date', inplace = True)\n",
    "\n",
    "#look at dataframe\n",
    "precip_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort dataframe\n",
    "precip_df = precip_df.sort_values(by = 'date')\n",
    "precip_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot data\n",
    "fig, ax = plt.subplots(figsize = (15, 7))\n",
    "# prcp_year_df.plot(x='date',y='prcp', figsize = (18,8), rot = 340)\n",
    "precip_df.plot(ax = ax, x_compat = True, rot =340)\n",
    "\n",
    "#set title and labels\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Precipitation (inches)')\n",
    "ax.set_title(\"Precipitation 8/24/2016 - 8/23/2017\")\n",
    "\n",
    "#save figure\n",
    "# plt.savefig(\"Images/precip.png\")\n",
    "\n",
    "#plot figure\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# x_axis = precip_df['date']\n",
    "# tick_locations = [value for value in x_axis]\n",
    "# y_axis = precip_df['prcp']\n",
    "# plt.bar(x_axis, y_axis, color=[\"blue\"], alpha=1, align=\"center\")\n",
    "\n",
    "\n",
    "# # Create Ticks for Bar Chart's x_axis\n",
    "# plt.xticks(tick_locations, x_axis, rotation=85, fontsize=12)\n",
    "\n",
    "# # Set Labels & Title\n",
    "# plt.ylabel(\"Precipitation\", fontsize=12)\n",
    "# plt.xlabel(\"Date\",fontsize=12)\n",
    "# plt.title(\"Average Employee Salary by Title\",fontsize=12)\n",
    "\n",
    "# # plt.text(45, 35, \"Employee Titles\", fontsize=12, alpha=0.75 )\n",
    "\n",
    "# # Save Figure\n",
    "plt.savefig(\"..//Advanced-Data-Storage-and-Retrieval/Precipitation Analysis.png\")\n",
    "\n",
    "# # Show plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas to calculate the summary statistics for the precipitation data\n",
    "precip_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Station Analysis\n",
    "We wish to investigate the actual stations themselves now.\n",
    "\n",
    "First, we want to know how many stations there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design a query to show how many stations are available in this dataset?\n",
    "number_of_stations = session.query(Station.id).distinct().count()\n",
    "# number_of_stations\n",
    "print(f\"The number of stations available: {number_of_stations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the most active stations? (i.e. what stations have the most rows)?\n",
    "# List the stations and the counts in descending order.\n",
    "active_station_counts = session.query(Station.station, func.count(Measurement.id)).select_from(Measurement).\\\n",
    "    join(Station, Measurement.station == Station.station).group_by(Station.station).\\\n",
    "    order_by(func.count(Measurement.id).desc()).all()\n",
    "\n",
    "for result in active_station_counts:\n",
    "    print(f\"Station:{result[0]}  Count:{result[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the station id from the previous query, calculate the lowest temperature recorded, \n",
    "# highest temperature recorded, and average temperature most active station?\n",
    "most_active_station = 'USC00519281'\n",
    "summary_temps = session.query(func.min(Measurement.tobs), func.max(Measurement.tobs), func.avg(Measurement.tobs)).\\\n",
    "    filter(Measurement.station == most_active_station).all()                      \n",
    "print(f\"Lowest Temperature:  {round(summary_temps[0][0],2)} Fahrenheit\")\n",
    "print(f\"Highest Temperature: {round(summary_temps[0][1],2)} Fahrenheit\")\n",
    "print(f\"Average Temperature: {round(summary_temps[0][2],2)} Fahrenheit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the station with the highest number of temperature observations.\n",
    "# Query the last 12 months of temperature observation data for this station and plot the results as a histogram\n",
    "highest_temp_obs = session.query(Measurement.date, Measurement.tobs).filter(Measurement.station == most_active_station).\\\n",
    "filter(func. strftime(\"%Y-%m-%d\", Measurement.date) >= dt.date(2016,8,23)).all()\n",
    "\n",
    "highest_temps_obs_df = pd.DataFrame(highest_temp_obs, columns = [\"date\", \"temperature\"])\n",
    "highest_temps_obs_df.head()\n",
    "\n",
    "\n",
    "#plot data\n",
    "fig, ax = plt.subplots(figsize = (10,7))\n",
    "highest_temps_obs_df.plot.hist(bins=12, ax = ax)\n",
    "\n",
    "#set title and labels\n",
    "ax.set_xlabel('Temperature (Fahrenheit)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title(\"Temperatures 2016 - 2017\")\n",
    "\n",
    "#save figure\n",
    "plt.savefig(\"..//Advanced-Data-Storage-and-Retrieval/Station with highest temperature Analysis.png\")\n",
    "\n",
    "#plot figure\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Optional: Other Recommended Analyses\n",
    "    Temperature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function called `calc_temps` will accept start date and end date in the format '%Y-%m-%d' \n",
    "# and return the minimum, average, and maximum temperatures for that range of dates\n",
    "def calc_temps(start_date, end_date):\n",
    "    \"\"\"TMIN, TAVG, and TMAX for a list of dates.\n",
    "    \n",
    "    Args:\n",
    "        start_date (string): A date string in the format %Y-%m-%d\n",
    "        end_date (string): A date string in the format %Y-%m-%d\n",
    "        \n",
    "    Returns:\n",
    "        TMIN, TAVE, and TMAX\n",
    "    \"\"\"\n",
    "    \n",
    "    return session.query(func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)).\\\n",
    "        filter(Measurement.date >= start_date).filter(Measurement.date <= end_date).all()\n",
    "\n",
    "# function usage example\n",
    "print(calc_temps('2012-02-28', '2012-03-05'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your previous function `calc_temps` to calculate the tmin, tavg, and tmax \n",
    "# for your trip using the previous year's data for those same dates.\n",
    "trip_temps = calc_temps(\"2017-02-10\", \"2017-02-25\")\n",
    "\n",
    "print(f\"Lowest Temperature: {trip_temps[0][0]} Fahrenheit\")\n",
    "print(f\"Average Temperature: {(trip_temps[0][1],2)} Fahrenheit\")\n",
    "print(f\"Highest Temperature: {trip_temps[0][2]} Fahrenheit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results from your previous query as a bar chart. \n",
    "# Use \"Trip Avg Temp\" as your Title\n",
    "# Use the average temperature for the y value\n",
    "# Use the peak-to-peak (tmax-tmin) value as the y error bar (yerr)\n",
    "pk_to_pk = trip_temps[0][2] - trip_temps[0][0]\n",
    "avg_temp = trip_temps[0][1]\n",
    "\n",
    "#plot figure\n",
    "fig, ax = plt.subplots(figsize = (5, 10))\n",
    "\n",
    "ax.bar(1, avg_temp, yerr = pk_to_pk/2, width = 0.4)\n",
    "\n",
    "#set labels\n",
    "ax.set_xticks([1])\n",
    "ax.set_xticklabels([\"\"])\n",
    "ax.set_title('Trip Avg Temp')\n",
    "ax.set_ylabel('Temperature (Fahrenheit)')\n",
    "\n",
    "#save fig\n",
    "# plt.savefig(\"Images/tempbar\")\n",
    "\n",
    "#show figure\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Challenge Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query that will calculate the daily normals \n",
    "# (i.e. the averages for tmin, tmax, and tavg for all historic data matching a specific month and day)\n",
    "\n",
    "def daily_normals(date):\n",
    "    \"\"\"Daily Normals.\n",
    "    \n",
    "    Args:\n",
    "        date (str): A date string in the format '%m-%d'\n",
    "        \n",
    "    Returns:\n",
    "        A list of tuples containing the daily normals, tmin, tavg, and tmax\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sel = [func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)]\n",
    "    return session.query(*sel).filter(func.strftime(\"%m-%d\", Measurement.date) == date).all()\n",
    "    \n",
    "daily_normals(\"01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the daily normals for your trip\n",
    "# push each tuple of calculations into a list called `normals`\n",
    "\n",
    "# Set the start and end date of the trip\n",
    "\n",
    "# Use the start and end date to create a range of dates\n",
    "\n",
    "# Stip off the year and save a list of %m-%d strings\n",
    "\n",
    "# Loop through the list of %m-%d strings and calculate the normals for each date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previous query results into a Pandas DataFrame and add the `trip_dates` range as the `date` index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the daily normals as an area plot with `stacked=False`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total amount of rainfall per weather station for your trip dates using the previous year's matching dates.\n",
    "# Sort this in descending order by precipitation amount and list the station, name, latitude, longitude, and elevation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.12.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
